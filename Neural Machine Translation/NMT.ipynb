{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding,LSTM,Dropout,Dense,Layer\n",
    "from keras import Model,Input\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import collections\n",
    "import numpy as np\n",
    "import time\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageDict():\n",
    "    def __init__(self, sents):\n",
    "        word_counter = collections.Counter(tok.lower() for sent in sents for tok in sent)\n",
    "\n",
    "        self.vocab = []\n",
    "        self.vocab.append('<pad>') #zero paddings\n",
    "        self.vocab.append('<unk>')\n",
    "        # add only words that appear at least 10 times in the corpus\n",
    "        self.vocab.extend([t for t,c in word_counter.items() if c > 10])\n",
    "\n",
    "        self.word2ids = {w:id for id, w in enumerate(self.vocab)}\n",
    "        self.UNK = self.word2ids['<unk>']\n",
    "        self.PAD = self.word2ids['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(source_path,target_path, max_num_examples=30000):\n",
    "    ''' This helper method reads from the source and target files to load max_num_examples \n",
    "    sentences, split them into train, development and testing and return relevant data.\n",
    "    Inputs:\n",
    "    source_path (string): the full path to the source data, SOURCE_PATH\n",
    "    target_path (string): the full path to the target data, TARGET_PATH\n",
    "    Returns:\n",
    "    train_data (list): a list of 3 elements: source_words, target words, target word labels\n",
    "    dev_data (list): a list of 2 elements - source words, target word labels\n",
    "    test_data (list): a list of 2 elements - source words, target word labels\n",
    "    source_dict (LanguageDict): a LanguageDict object for the source language, Vietnamese.\n",
    "    target_dict (LanguageDict): a LanguageDict object for the target language, English.\n",
    "    ''' \n",
    "    # source_lines/target lines are list of strings such that each string is a sentence in the\n",
    "    # corresponding file. len(source/target_lines) <= max_num_examples\n",
    "    source_lines = open(source_path,encoding='utf8').readlines()\n",
    "    target_lines = open(target_path,encoding='utf8').readlines()\n",
    "    assert len(source_lines) == len(target_lines)\n",
    "    if max_num_examples > 0:\n",
    "        max_num_examples = min(len(source_lines), max_num_examples)\n",
    "        source_lines = source_lines[:max_num_examples]\n",
    "        target_lines = target_lines[:max_num_examples]\n",
    "\n",
    "    # strip trailing/leading whitespaces and tokenize each sentence. \n",
    "    source_sents = [[tok.lower() for tok in sent.strip().split(' ')] for sent in source_lines]\n",
    "    target_sents = [[tok.lower() for tok in sent.strip().split(' ')] for sent in target_lines]\n",
    "    # for the target sentences, add <start> and <end> tokens to each sentence \n",
    "    for sent in target_sents:\n",
    "        sent.append('<end>')\n",
    "        sent.insert(0,'<start>')\n",
    "\n",
    "    # create the LanguageDict objects for each file\n",
    "    source_lang_dict = LanguageDict(source_sents)\n",
    "    target_lang_dict = LanguageDict(target_sents)\n",
    "\n",
    "\n",
    "    # for the source sentences.\n",
    "    # we'll use this to split into train/dev/test \n",
    "    unit = len(source_sents)//10\n",
    "    # get the sents-as-ids for each sentence\n",
    "    source_words = [[source_lang_dict.word2ids.get(tok,source_lang_dict.UNK) for tok in sent] for sent in source_sents]\n",
    "    # 8 parts (80%) of the sentences go to the training data. pad upto maximum sentence length\n",
    "    source_words_train = pad_sequences(source_words[:8*unit],padding='post')\n",
    "    # 1 parts (10%) of the sentences go to the dev data. pad upto maximum sentence length\n",
    "    source_words_dev = pad_sequences(source_words[8*unit:9*unit],padding='post')\n",
    "    # 1 parts (10%) of the sentences go to the test data. pad upto maximum sentence length\n",
    "    source_words_test = pad_sequences(source_words[9*unit:],padding='post')\n",
    "\n",
    "\n",
    "    eos = target_lang_dict.word2ids['<end>']\n",
    "    # for each sentence, get the word index for the tokens from <start> to up to but not including <end>,\n",
    "    target_words = [[target_lang_dict.word2ids.get(tok,target_lang_dict.UNK) for tok in sent[:-1]] for sent in target_sents]\n",
    "    # select the training set and pad the sentences\n",
    "    target_words_train = pad_sequences(target_words[:8*unit],padding='post')\n",
    "    # the label for each target word is the next word after it\n",
    "    target_words_train_labels = [sent[1:]+[eos] for sent in target_words[:8*unit]]\n",
    "    # pad the labels. Dim = [num_sents, max_sent_lenght]\n",
    "    target_words_train_labels = pad_sequences(target_words_train_labels,padding='post')\n",
    "    # expand dimensions Dim = [num_sents, max_sent_lenght, 1]. \n",
    "    target_words_train_labels = np.expand_dims(target_words_train_labels,axis=2)\n",
    "\n",
    "    # get the labels for the dev and test data. No need for inputs here. no need to expand dimensions\n",
    "    target_words_dev_labels = pad_sequences([sent[1:] + [eos] for sent in target_words[8 * unit:9 * unit]], padding='post')\n",
    "    target_words_test_labels = pad_sequences([sent[1:] + [eos] for sent in target_words[9 * unit:]], padding='post')\n",
    "\n",
    "    # we have our data.\n",
    "    train_data = [source_words_train,target_words_train,target_words_train_labels]\n",
    "    dev_data = [source_words_dev,target_words_dev_labels]\n",
    "    test_data = [source_words_test,target_words_test_labels]\n",
    "\n",
    "    return train_data,dev_data,test_data,source_lang_dict,target_lang_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttentionLayer(Layer):\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if mask == None:\n",
    "            return None\n",
    "        return mask[1]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[1][0],input_shape[1][1],input_shape[1][2]*2)\n",
    "\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        encoder_outputs, decoder_outputs = inputs\n",
    "        \n",
    "        ## encoder_outputs =  [batch_size,max_source_sent_len, hidden_size]      \n",
    "        ## decoder_outputs =  [batch_size, hidden_size, max_target_sent_len]\n",
    "        ## luong_score = [batch_size,max_source_sent_len, max_target_sent_len]\n",
    "        \n",
    "        \"\"\"\n",
    "##########################################        Task 3 attention         ##########################################\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        decoder_outputs_per = K.permute_dimensions(decoder_outputs, (0, 2, 1))\n",
    "        luong_score = K.batch_dot(encoder_outputs,decoder_outputs_per)\n",
    "        encoder_outputs = K.softmax(encoder_outputs, axis=1)\n",
    "        encoder_vector = (K.expand_dims(encoder_outputs,2))*(K.expand_dims(luong_score,3))\n",
    "        encoder_vector = K.sum(encoder_vector, axis = 1)\n",
    "       \n",
    "        \n",
    "#         print(\"decoder_outputs shape:\",decoder_outputs.shape )\n",
    "#         print(\"decoder_outputs_per shape:\",decoder_outputs_per.shape )\n",
    "#         print(\"encoder_vector shape:\",encoder_vector.shape )\n",
    "        \n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "###############################################        End Task 3         ###########################################\n",
    "        \"\"\"\n",
    "        # [batch,max_dec,2*emb]              \n",
    "     \n",
    "        new_decoder_outputs = K.concatenate([decoder_outputs, encoder_vector])\n",
    "        return new_decoder_outputs\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NmtModel(object):\n",
    "    def __init__(self,source_dict,target_dict,use_attention):\n",
    "        ''' The model initialization function initializes network parameters.\n",
    "        Inputs:\n",
    "          source_dict (LanguageDict): a LanguageDict object for the source language, Vietnamese.\n",
    "          target_dict (LanguageDict): a LanguageDict object for the target language, English.\n",
    "          use_attention (bool): if True, use attention.\n",
    "        Returns:\n",
    "          None.\n",
    "        '''\n",
    "        # the number of hidden units used by the LSTM\n",
    "        self.hidden_size = 200\n",
    "        # the size of the word embeddings being used\n",
    "        self.embedding_size = 100\n",
    "        # the dropout rate for the hidden layers\n",
    "        self.hidden_dropout_rate=0.2\n",
    "        # the dropout rate for the word embeddings\n",
    "        self.embedding_dropout_rate = 0.2\n",
    "        # batch size\n",
    "        self.batch_size = 100\n",
    "\n",
    "        # the maximum length of the target sentences\n",
    "        self.max_target_step = 30\n",
    "\n",
    "        # vocab size for source and target; we'll use everything we receive\n",
    "        self.vocab_target_size = len(target_dict.vocab)\n",
    "        self.vocab_source_size = len(source_dict.vocab)\n",
    "        \n",
    "        # intances of the dictionaries\n",
    "        self.target_dict = target_dict\n",
    "        self.source_dict = source_dict\n",
    "\n",
    "        # special tokens to indicate sentence starts and ends.\n",
    "        self.SOS = target_dict.word2ids['<start>']\n",
    "        self.EOS = target_dict.word2ids['<end>']\n",
    "\n",
    "        # use attention or no\n",
    "        self.use_attention = use_attention\n",
    "\n",
    "        print(\"number of tokens in source: %d, number of tokens in target:%d\" % (self.vocab_source_size,self.vocab_target_size))\n",
    "\n",
    "\n",
    "\n",
    "    def build(self):\n",
    "        #-------------------------Train Models------------------------------\n",
    "        source_words = Input(shape=(None,),dtype='int32')\n",
    "        target_words = Input(shape=(None,), dtype='int32')\n",
    "\n",
    "        \"\"\"\n",
    "#########################################################     Task 1 encoder   #######################################\n",
    "\n",
    "        Start\n",
    "        \"\"\"\n",
    "        # The train encoder\n",
    "        # (a.) Create two randomly initialized embedding lookups, one for the source, another for the target. \n",
    "        print('Task 1(a): Creating the embedding lookups...')\n",
    "        source_embeddings = Embedding(input_dim = self.vocab_source_size, \n",
    "                                      output_dim =self.embedding_size, mask_zero=True)\n",
    "        target_embeddings = Embedding(input_dim = self.vocab_target_size,\n",
    "                                      output_dim =self.embedding_size, mask_zero=True)\n",
    "\n",
    "        # (b.) Look up the embeddings for source words and for target words. Apply dropout each encoded input\n",
    "        print('\\nTask 1(b): Looking up source and target words...')\n",
    "        source_word_embeddings = source_embeddings(source_words)\n",
    "        source_word_embeddings = (Dropout(self.embedding_dropout_rate))(source_word_embeddings)\n",
    "        \n",
    "        target_words_embeddings = target_embeddings(target_words)\n",
    "        target_words_embeddings = (Dropout(self.embedding_dropout_rate))(target_words_embeddings)\n",
    "        \n",
    "        \n",
    "        # (c.) An encoder LSTM() with return sequences set to True\n",
    "        print('\\nTask 1(c): Creating an encoder')\n",
    "        encoder_lstm = LSTM(self.hidden_size,return_sequences=True,return_state=True,dropout =self.hidden_dropout_rate )\n",
    "        encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(source_word_embeddings)\n",
    "        \"\"\"\n",
    "        \n",
    "#########################################################        End Task 1       #######################################\n",
    "        \"\"\"\n",
    "        encoder_states = [encoder_state_h,encoder_state_c]\n",
    "\n",
    "        # The train decoder\n",
    "        decoder_lstm = LSTM(self.hidden_size,recurrent_dropout=self.hidden_dropout_rate,return_sequences=True,return_state=True)\n",
    "        decoder_outputs_train,_,_ = decoder_lstm(target_words_embeddings,initial_state=encoder_states)\n",
    "        print(\"decoder_outputs_train:\", decoder_outputs_train)\n",
    "        if self.use_attention:\n",
    "            decoder_attention = AttentionLayer()\n",
    "            decoder_outputs_train = decoder_attention([encoder_outputs,decoder_outputs_train])\n",
    "\n",
    "        decoder_dense = Dense(self.vocab_target_size,activation='softmax')\n",
    "        decoder_outputs_train = decoder_dense(decoder_outputs_train)\n",
    "\n",
    "        # compiling the train model.\n",
    "        adam = Adam(lr=0.01,clipnorm=5.0)\n",
    "        self.train_model = Model([source_words,target_words], decoder_outputs_train)\n",
    "        self.train_model.compile(optimizer=adam,loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # at this point you can print model summary for the train model\n",
    "        print('\\t\\t\\t\\t\\t\\t Train Model Summary.')\n",
    "        self.train_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "        #-------------------------Inference Models------------------------------\n",
    "        # The inference encoder \n",
    "        self.encoder_model = Model(source_words,[encoder_outputs,encoder_state_h,encoder_state_c])\n",
    "        # at this point you can print the summary for the encoder model.\n",
    "        print('\\t\\t\\t\\t\\t\\t Inference Time Encoder Model Summary.')\n",
    "        self.encoder_model.summary()\n",
    "\n",
    "        # The decoder model\n",
    "        # specifying the inputs to the decoder\n",
    "        decoder_state_input_h = Input(shape=(self.hidden_size,))\n",
    "        decoder_state_input_c = Input(shape=(self.hidden_size,))\n",
    "        encoder_outputs_input = Input(shape=(None,self.hidden_size,))\n",
    "\n",
    "        \"\"\"\n",
    "######################################        Task 2 decoder for inference     ####################################\n",
    "\n",
    "        Start\n",
    "        \"\"\"\n",
    "        # Task 2 (a.) Get the decoded outputs\n",
    "        print('\\n Putting together the decoder states')\n",
    "        \n",
    "        # get the inititial states for the decoder, decoder_states\n",
    "        # decoder states are the hidden and cell states from the training stage\n",
    "        decoder_states = [decoder_state_input_h,decoder_state_input_c]\n",
    "        \n",
    "        # use decoder states as input to the decoder lstm to get the decoder outputs, h, and c for test time inference\n",
    "        decoder_outputs_test,decoder_state_output_h, decoder_state_output_c = decoder_lstm(target_words_embeddings,\n",
    "                                                                                           initial_state=decoder_states)\n",
    "\n",
    "\n",
    "        # Task 2 (b.) Add attention if attention\n",
    "        if self.use_attention:\n",
    "            decoder_attention = AttentionLayer()\n",
    "            decoder_outputs_test = decoder_attention([encoder_outputs_input,decoder_outputs_test])\n",
    "        \n",
    "\n",
    "        # Task 2 (c.) pass the decoder_outputs_test (with or without attention) to the decoder dense layer\n",
    "        decoder_dense = Dense(self.vocab_target_size,activation='softmax')\n",
    "        decoder_outputs_test = decoder_dense(decoder_outputs_test)\n",
    "        \n",
    "        \"\"\"\n",
    "#############################################        End Task 2         ###########################################\n",
    "        \"\"\"\n",
    "        # put the model together\n",
    "        self.decoder_model = Model([target_words,decoder_state_input_h,decoder_state_input_c,encoder_outputs_input],\n",
    "                                   [decoder_outputs_test,decoder_state_output_h,decoder_state_output_c])\n",
    "        # you can now view the model summary\n",
    "        print('\\t\\t\\t\\t\\t\\t Decoder Inference Model summary')\n",
    "        print(self.decoder_model.summary())\n",
    "\n",
    "\n",
    "\n",
    "    def time_used(self, start_time):\n",
    "        curr_time = time.time()\n",
    "        used_time = curr_time-start_time\n",
    "        m = used_time // 60\n",
    "        s = used_time - 60 * m\n",
    "        return \"%d m %d s\" % (m, s)\n",
    "\n",
    "\n",
    "\n",
    "    def train(self,train_data,dev_data,test_data, epochs):\n",
    "        start_time = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Starting training epoch {}/{}\".format(epoch + 1, epochs))\n",
    "            epoch_time = time.time()\n",
    "            source_words_train, target_words_train, target_words_train_labels = train_data\n",
    "\n",
    "            self.train_model.fit([source_words_train,target_words_train],target_words_train_labels,batch_size=self.batch_size)\n",
    "\n",
    "            print(\"Time used for epoch {}: {}\".format(epoch + 1, self.time_used(epoch_time)))\n",
    "            dev_time = time.time()\n",
    "            print(\"Evaluating on dev set after epoch {}/{}:\".format(epoch + 1, epochs))\n",
    "            self.eval(dev_data)\n",
    "            print(\"Time used for evaluate on dev set: {}\".format(self.time_used(dev_time)))\n",
    "\n",
    "        print(\"Training finished!\")\n",
    "        print(\"Time used for training: {}\".format(self.time_used(start_time)))\n",
    "\n",
    "        print(\"Evaluating on test set:\")\n",
    "        test_time = time.time()\n",
    "        self.eval(test_data)\n",
    "        print(\"Time used for evaluate on test set: {}\".format(self.time_used(test_time)))\n",
    "\n",
    "\n",
    "\n",
    "    def get_target_sentences(self, sents,vocab,reference=False):\n",
    "        str_sents = []\n",
    "        num_sent, max_len = sents.shape\n",
    "        for i in range(num_sent):\n",
    "            str_sent = []\n",
    "            for j in range(max_len):\n",
    "                t = sents[i,j].item()\n",
    "                if t == self.SOS:\n",
    "                    continue\n",
    "                if t == self.EOS:\n",
    "                    break\n",
    "\n",
    "                str_sent.append(vocab[t])\n",
    "            if reference:\n",
    "                str_sents.append([str_sent])\n",
    "            else:\n",
    "                str_sents.append(str_sent)\n",
    "        return str_sents\n",
    "\n",
    "\n",
    "    def eval(self, dataset):\n",
    "        # get the source words and target_word_labels for the eval dataset\n",
    "        source_words, target_words_labels = dataset\n",
    "        vocab = self.target_dict.vocab\n",
    "\n",
    "        # using the same encoding network used during training time, encode the training\n",
    "        encoder_outputs, state_h,state_c = self.encoder_model.predict(source_words,batch_size=self.batch_size)\n",
    "        # for max_target_step steps, feed the step target words into the decoder.\n",
    "        predictions = []\n",
    "        step_target_words = np.ones([source_words.shape[0],1]) * self.SOS\n",
    "        for _ in range(self.max_target_step):\n",
    "\n",
    "            step_decoder_outputs, state_h,state_c = self.decoder_model.predict([step_target_words,state_h,state_c,encoder_outputs],batch_size=self.batch_size)\n",
    "            step_target_words = np.argmax(step_decoder_outputs,axis=2)\n",
    "            predictions.append(step_target_words)\n",
    "\n",
    "        # predictions is a [time_step x batch_size x 1] array. We use get_target_sentence() to recover the batch_size sentences\n",
    "        candidates = self.get_target_sentences(np.concatenate(predictions,axis=1),vocab)\n",
    "        references = self.get_target_sentences(target_words_labels,vocab,reference=True)\n",
    "        \n",
    "        print(\"Predicted Samples:\", candidates[:2])\n",
    "        print(\"Reference Samples:\", references[:2])\n",
    "        \n",
    "        \n",
    "        weights=(0.25, 0.25, 0.25, 0.25)\n",
    "        chencherry = SmoothingFunction()\n",
    "        # score using nltk bleu scorer\n",
    "        score = corpus_bleu(references,candidates, smoothing_function=chencherry.method7)\n",
    "        #score1 = corpus_bleu(references,candidates, smoothing_function=chencherry.method3)\n",
    "        #score4 = corpus_bleu(references,candidates, smoothing_function=chencherry.method5)\n",
    "        #score = corpus_bleu(references,candidates)\n",
    "        #print(\"references\",references)\n",
    "        #print(\"candidates\",candidates)\n",
    "        print(\"Model BLEU score: %.2f\" % (score*100.0))\n",
    "        #print(\"3Model BLEU score: %.2f\" % (score1*100.0))\n",
    "        #print(\"5Model BLEU score: %.2f\" % (score4*100.0))\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(source_path, target_path, use_attention):\n",
    "    max_example = 30000\n",
    "    print('loading dictionaries')\n",
    "    train_data, dev_data, test_data, source_dict, target_dict = load_dataset(source_path,target_path,max_num_examples=max_example)\n",
    "    print(\"read %d/%d/%d train/dev/test batches\" % (len(train_data[0]),len(dev_data[0]), len(test_data[0])))\n",
    "\n",
    "    model = NmtModel(source_dict,target_dict,use_attention)\n",
    "    model.build()\n",
    "    model.train(train_data,dev_data,test_data, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH =  'data.30.vi'\n",
    "TARGET_PATH =  'data.30.en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data,dev_data,test_data,source_lang_dict,target_lang_dict =load_dataset(SOURCE_PATH,TARGET_PATH, max_num_examples=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dictionaries\n",
      "read 24000/3000/3000 train/dev/test batches\n",
      "number of tokens in source: 2034, number of tokens in target:2506\n",
      "Task 1(a): Creating the embedding lookups...\n",
      "\n",
      "Task 1(b): Looking up source and target words...\n",
      "\n",
      "Task 1(c): Creating an encoder\n",
      "decoder_outputs_train: KerasTensor(type_spec=TensorSpec(shape=(None, None, 200), dtype=tf.float32, name=None), name='lstm_205/transpose_2:0', description=\"created by layer 'lstm_205'\")\n",
      "\t\t\t\t\t\t Train Model Summary.\n",
      "Model: \"model_131\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_339 (InputLayer)          [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_206 (Embedding)       (None, None, 100)    203400      input_339[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_340 (InputLayer)          [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_204 (Dropout)           (None, None, 100)    0           embedding_206[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_207 (Embedding)       (None, None, 100)    250600      input_340[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_204 (LSTM)                 [(None, None, 200),  240800      dropout_204[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_205 (Dropout)           (None, None, 100)    0           embedding_207[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_205 (LSTM)                 [(None, None, 200),  240800      dropout_205[0][0]                \n",
      "                                                                 lstm_204[0][1]                   \n",
      "                                                                 lstm_204[0][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer_90 (AttentionLa (None, None, 400)    0           lstm_204[0][0]                   \n",
      "                                                                 lstm_205[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_119 (Dense)               (None, None, 2506)   1004906     attention_layer_90[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 1,940,506\n",
      "Trainable params: 1,940,506\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\t\t\t\t\t\t Inference Time Encoder Model Summary.\n",
      "Model: \"model_132\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_339 (InputLayer)       [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_206 (Embedding)    (None, None, 100)         203400    \n",
      "_________________________________________________________________\n",
      "dropout_204 (Dropout)        (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "lstm_204 (LSTM)              [(None, None, 200), (None 240800    \n",
      "=================================================================\n",
      "Total params: 444,200\n",
      "Trainable params: 444,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      " Putting together the decoder states\n",
      "\t\t\t\t\t\t Decoder Inference Model summary\n",
      "Model: \"model_133\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_340 (InputLayer)          [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_207 (Embedding)       (None, None, 100)    250600      input_340[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_205 (Dropout)           (None, None, 100)    0           embedding_207[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_341 (InputLayer)          [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_342 (InputLayer)          [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_343 (InputLayer)          [(None, None, 200)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_205 (LSTM)                 [(None, None, 200),  240800      dropout_205[0][0]                \n",
      "                                                                 input_341[0][0]                  \n",
      "                                                                 input_342[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer_91 (AttentionLa (None, None, 400)    0           input_343[0][0]                  \n",
      "                                                                 lstm_205[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, None, 2506)   1004906     attention_layer_91[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 1,496,306\n",
      "Trainable params: 1,496,306\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Starting training epoch 1/1\n",
      "240/240 [==============================] - 104s 418ms/step - loss: 2.5610 - accuracy: 0.1692\n",
      "Time used for epoch 1: 1 m 44 s\n",
      "Evaluating on dev set after epoch 1/1:\n",
      "Predicted Samples: [['proteins', 'saving', 'weeks', 'surfaces', 'surfaces', 'surfaces', 'surfaces', 'surfaces', '50', 'surfaces', 'at', 'wait', '80', 'when', 'equivalent', 'at', 'center', 'at', 'wait', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town'], ['others', 'slowly', 'layers', 'surfaces', 'slowly', 'layers', ':', 'search', 'capable', 'capable', 'come', 'learning', 'draw', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town']]\n",
      "Reference Samples: [[['there', 'are', 'four', '<unk>', '<unk>', 'that', ',', 'each', 'time', 'this', 'ring', '<unk>', 'it', ',', 'as', 'it', '<unk>', 'the', '<unk>', 'of', 'the', 'display', ',', 'it', '<unk>', 'up', 'a', 'position', 'signal', '.']], [['but', 'this', 'is', 'really', 'just', 'the', 'beginning', '.']]]\n",
      "Model BLEU score: 6.46\n",
      "Time used for evaluate on dev set: 0 m 11 s\n",
      "Training finished!\n",
      "Time used for training: 1 m 56 s\n",
      "Evaluating on test set:\n",
      "Predicted Samples: [['allows', 'younger', 'saving', 'saving', 'driver', 'saving', 'father', 'at', 'wait', 'right', '12', 'at', 'wait', 'right', '12', 'at', 'wait', '80', 'when', 'equivalent', 'at', 'wait', '80', 'when', 'equivalent', 'at', 'center', 'at', 'wait', 'town'], ['allows', 'younger', 'saving', 'operating', 'sort', 'way', 'afternoon', 'learning', 'draw', 'listen', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town', 'town']]\n",
      "Reference Samples: [[['the', 'second', 'quote', 'is', 'from', 'the', 'head', 'of', 'the', 'u.k.', 'financial', 'services', '<unk>', '.']], [['it', 'gets', 'worse', '.']]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model BLEU score: 6.45\n",
      "Time used for evaluate on test set: 0 m 11 s\n"
     ]
    }
   ],
   "source": [
    "main(SOURCE_PATH, TARGET_PATH, use_attention= True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
